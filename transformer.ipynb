{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f39f763",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch import tensor\n",
    "from torch.functional import F\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision import models\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, root_mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import copy\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import h5py\n",
    "from Helpers import Params, collate_fn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4586b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBar:\n",
    "    def __init__(self, total: int):\n",
    "        self.total = total\n",
    "        self.current = 0\n",
    "        self.last_progress = 0\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def update(self, current: int, epochs: str):\n",
    "        self.current = current\n",
    "        progress = (self.current / self.total) * 100\n",
    "        if int(progress) > self.last_progress:\n",
    "            elapsed_time = time.time() - self.start_time\n",
    "            print(\n",
    "                f'\\rEpoch: {epochs.rjust(7)} {str(int(progress)).rjust(3)}% | Elapsed: {str(int(elapsed_time)).rjust(3)}s', end='')\n",
    "            self.last_progress = int(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4383336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=False):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4c675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHistory:\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': []\n",
    "        }\n",
    "\n",
    "    def update(self, train_loss: float, train_accuracy: float, val_loss: float, val_accuracy: float):\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['train_accuracy'].append(train_accuracy)\n",
    "        self.history['val_loss'].append(val_loss)\n",
    "        self.history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "    def plot(self):\n",
    "        epochs = range(1, len(self.history['train_loss']) + 1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.history['train_loss'], label='Train Loss')\n",
    "        plt.plot(epochs, self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(\n",
    "            epochs, self.history['train_accuracy'], label='Train Accuracy')\n",
    "        plt.plot(epochs, self.history['val_accuracy'],\n",
    "                 label='Validation Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abfad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHistory:\n",
    "    def __init__(self):\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_accuracy': [],\n",
    "            'val_loss': [],\n",
    "            'val_accuracy': []\n",
    "        }\n",
    "\n",
    "    def update(self, train_loss: float, train_accuracy: float, val_loss: float, val_accuracy: float):\n",
    "        self.history['train_loss'].append(train_loss)\n",
    "        self.history['train_accuracy'].append(train_accuracy)\n",
    "        self.history['val_loss'].append(val_loss)\n",
    "        self.history['val_accuracy'].append(val_accuracy)\n",
    "\n",
    "    def get_history(self):\n",
    "        return self.history\n",
    "\n",
    "    def plot(self):\n",
    "        epochs = range(1, len(self.history['train_loss']) + 1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Plot loss\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.history['train_loss'], label='Train Loss')\n",
    "        plt.plot(epochs, self.history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Plot accuracy\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(\n",
    "            epochs, self.history['train_accuracy'], label='Train Accuracy')\n",
    "        plt.plot(epochs, self.history['val_accuracy'],\n",
    "                 label='Validation Accuracy')\n",
    "        plt.title('Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d887b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def update(self, loss: float, accuracy: float):\n",
    "        self.losses.append(loss)\n",
    "        self.accuracies.append(accuracy)\n",
    "\n",
    "    def get_average_loss(self):\n",
    "        return sum(self.losses) / len(self.losses) if self.losses else 0.0\n",
    "\n",
    "    def get_average_accuracy(self):\n",
    "        return sum(self.accuracies) / len(self.accuracies) if self.accuracies else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848ed791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator:\n",
    "    def __init__(self, model: nn.Module, criterion: nn.CrossEntropyLoss, device: torch.device):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def validate(self, val_loader: DataLoader) -> tuple:\n",
    "        self.model.eval()\n",
    "        metrics_tracker = MetricsTracker()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for image, midi in val_loader:\n",
    "                image: torch.Tensor = image.to(self.device)\n",
    "                midi: torch.Tensor = midi.to(self.device)\n",
    "\n",
    "                input_tokens: torch.Tensor = midi[:, :-1]\n",
    "                target_tokens: torch.Tensor = midi[:, 1:]\n",
    "                target_tokens = target_tokens.reshape(-1)\n",
    "\n",
    "                output: torch.Tensor = self.model(image, input_tokens)\n",
    "                output = output.reshape(-1, output.shape[-1])\n",
    "\n",
    "                loss: torch.Tensor = self.criterion(output, target_tokens)\n",
    "                accuracy = (output.argmax(dim=1) ==\n",
    "                            target_tokens).float().mean().item()\n",
    "\n",
    "                metrics_tracker.update(loss.item(), accuracy)\n",
    "\n",
    "        avg_loss = metrics_tracker.get_average_loss()\n",
    "        avg_accuracy = metrics_tracker.get_average_accuracy()\n",
    "\n",
    "        return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099553aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, max_len: int):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model).to(device)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(\n",
    "            0, d_model, 2).float() * -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb56fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidatorWithOutputs:\n",
    "    def __init__(self, model: nn.Module, criterion: nn.CrossEntropyLoss, device: torch.device):\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    def validate(self, val_loader: DataLoader) -> tuple:\n",
    "        self.model.eval()\n",
    "        outputs = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for image, midi in val_loader:\n",
    "                image: torch.Tensor = image.to(self.device)\n",
    "                midi: torch.Tensor = midi.to(self.device)\n",
    "\n",
    "                input_tokens: torch.Tensor = midi[:, :-1]\n",
    "                target_tokens: torch.Tensor = midi[:, 1:]\n",
    "                target_tokens = target_tokens.reshape(-1)\n",
    "\n",
    "                output: torch.Tensor = self.model(image, input_tokens)\n",
    "                output = output.reshape(-1, output.shape[-1])\n",
    "\n",
    "                predicted = output.argmax(dim=1).cpu().tolist()\n",
    "                expected = target_tokens.cpu().tolist()\n",
    "\n",
    "                outputs.append((predicted, expected))\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ac0ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    criterion: nn.CrossEntropyLoss,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epochs: int,\n",
    "    device: torch.device = device,\n",
    "    history: TrainingHistory = None,\n",
    "    early_stopping: EarlyStopping = None\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        progress_bar = ProgressBar(len(train_loader))\n",
    "        metrics_tracker = MetricsTracker()\n",
    "        validator = Validator(model, criterion, device)\n",
    "        model.train()\n",
    "\n",
    "        for i, (image, word) in enumerate(train_loader):\n",
    "            image: torch.Tensor = image.to(device)\n",
    "            word: torch.Tensor = word.to(device)\n",
    "\n",
    "            input_tokens = word[:, :-1]\n",
    "            target_tokens = word[:, 1:]\n",
    "            # print(input_tokens)\n",
    "            # print(target_tokens)\n",
    "            target_tokens = target_tokens.reshape(-1)\n",
    "\n",
    "            output: torch.Tensor = model(image, input_tokens)\n",
    "            output = output.reshape(-1, output.shape[-1])\n",
    "\n",
    "            loss: torch.Tensor = criterion(output, target_tokens)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            accuracy = (output.argmax(dim=1) == target_tokens).float().mean().item()\n",
    "            metrics_tracker.update(loss.item(), accuracy)\n",
    "\n",
    "            progress_bar.update(i + 1, f'{epoch + 1}/{epochs}')\n",
    "\n",
    "        print(\n",
    "            f' | loss: {metrics_tracker.get_average_loss():.4f} - acc: {metrics_tracker.get_average_accuracy():.4f}', end='')\n",
    "        val_loss, val_acc = validator.validate(val_loader)\n",
    "        print(f' | val_loss: {val_loss:.4f} - val_acc: {val_acc:.4f}')\n",
    "\n",
    "        if history:\n",
    "            history.update(metrics_tracker.get_average_loss(\n",
    "            ), metrics_tracker.get_average_accuracy(), val_loss, val_acc)\n",
    "\n",
    "        if early_stopping:\n",
    "            early_stopping(val_loss, model)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97052507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandWritingDataset(datasets.ImageFolder):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        transform: transforms.Compose = None,\n",
    "        label_transofrm=None,\n",
    "        augument: transforms.Compose = None\n",
    "    ):\n",
    "        if augument is not None:\n",
    "            transform = transforms.Compose([\n",
    "                augument,\n",
    "                transform\n",
    "            ])\n",
    "\n",
    "        super(HandWritingDataset, self).__init__(root, transform=transform)\n",
    "        self.classes = [''.join([i if i != '_' else '' for i in word])\n",
    "                        for word in self.classes]\n",
    "        self.label_transform = label_transofrm\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = super(HandWritingDataset, self).__getitem__(index)\n",
    "        if self.label_transform is not None:\n",
    "            label = tensor(self.label_transform(self.classes[label]))\n",
    "        label = torch.cat((tensor([27]), label, tensor([28])))\n",
    "        return image, label\n",
    "\n",
    "    def create_sampler(self, epsilon: float = 0.004):\n",
    "        \"\"\"\n",
    "        epsilon: how strongly flatten the distribution? 0 means flat, the greater the more similar to original distribution, after 0.01 there is little difference\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(self.samples, columns=['filename', 'class'])\n",
    "        df['label'] = df['class'].apply(lambda x: ''.join(\n",
    "            [i for i in self.classes[x] if i != ' ']))\n",
    "        df['length'] = df['label'].apply(len)\n",
    "        length_df = df['length'].value_counts().sort_index().to_dict()\n",
    "        class_count = df['class'].value_counts().sort_index()\n",
    "        df['class_length'] = df['length'].map(length_df)\n",
    "        df['class_count'] = df['class'].apply(lambda x: class_count.iloc[x])\n",
    "        df['result'] = 1.0 / df['class_length'] + epsilon\n",
    "        return WeightedRandomSampler(df['result'].values, len(df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd79c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset:\n",
    "    def __init__(self, file_path: str, num_epochs: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_epochs (int): Number of epochs to split the dataset into.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        with h5py.File(file_path, 'r') as h5f:\n",
    "            h5_size = len(h5f['images'])\n",
    "            self.num_epochs = num_epochs\n",
    "            self.epoch_size = h5_size // num_epochs\n",
    "            self.current_epoch = 0\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,)),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.epoch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        with h5py.File(self.file_path, 'r') as h5f:\n",
    "            image = h5f['images'][self.current_epoch * self.epoch_size + index]\n",
    "            image = self.transform(image)\n",
    "            image = image.permute(1, 2, 0)\n",
    "            image = torch.stack([image[0]] * 3, dim=0)\n",
    "\n",
    "            label = h5f['labels'][self.current_epoch * self.epoch_size + index]\n",
    "            label = label[:np.argmax(label == 0)] if 0 in label else label\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            label = torch.cat((tensor([27]), label, tensor([28])))\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def next_epoch(self):\n",
    "        self.current_epoch = (self.current_epoch + 1) % self.num_epochs\n",
    "\n",
    "    def create_h5_sampler(self, epsilon: float = 0.004):\n",
    "        \"\"\"\n",
    "        epsilon: how strongly flatten the distribution? 0 means flat, the greater the more similar to original distribution, after 0.01 there is little difference\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame({'index': range(\n",
    "            self.current_epoch * self.epoch_size, (self.current_epoch + 1) * self.epoch_size)})\n",
    "        with h5py.File(self.file_path, 'r') as h5f:\n",
    "            labels = h5f['labels'][self.current_epoch *\n",
    "                                   self.epoch_size: (self.current_epoch + 1) * self.epoch_size]\n",
    "            df['length'] = (labels != 0).sum(axis=1)\n",
    "\n",
    "        length_df = df['length'].value_counts().sort_index()\n",
    "        length_dict = length_df.to_dict()\n",
    "\n",
    "        df['class_length'] = df['length'].map(length_dict)\n",
    "        df['result'] = 1.0 / df['class_length'] + epsilon\n",
    "\n",
    "        return WeightedRandomSampler(df['result'].values, len(df['result']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43bc23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandwritingTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        vocab_size: int,\n",
    "        d_model: int = 128,\n",
    "        nhead_en: int = 1,\n",
    "        num_layers_en: int = 1,\n",
    "        nhead_de: int = 1,\n",
    "        num_layers_de: int = 1,\n",
    "        dropout: float = 0.2  # Added dropout parameter\n",
    "    ):\n",
    "        super(HandwritingTransformer, self).__init__()\n",
    "\n",
    "        self.cnn = models.mobilenet_v2(pretrained=True).features[:4]\n",
    "        for param in self.cnn.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.input_size = nn.Linear(input_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, 200)\n",
    "\n",
    "        # Add LayerNorm and Dropout after input_size\n",
    "        self.input_norm = nn.LayerNorm(d_model)\n",
    "        self.input_dropout = nn.Dropout(dropout)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model, nhead_en, dropout=dropout, norm_first=True)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers_en)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model, nhead_de, dropout=dropout, norm_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers_de)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_decoder = PositionalEncoding(d_model, 20)\n",
    "\n",
    "        # Add LayerNorm and Dropout after embedding\n",
    "        self.embedding_norm = nn.LayerNorm(d_model)\n",
    "        self.embedding_dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.output = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src: torch.Tensor, tgt: torch.Tensor):\n",
    "        src = torch.stack([src[:, 0]] * 3, dim=1)\n",
    "        src = self.cnn(src)\n",
    "\n",
    "        src = src.flatten(1, 2)\n",
    "        src = src.permute(0, 2, 1)\n",
    "        src = self.input_size(src)\n",
    "\n",
    "        # Apply LayerNorm and Dropout after input_size\n",
    "        src = self.input_norm(src)\n",
    "        src = self.input_dropout(src)\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        src = src.permute(1, 0, 2)\n",
    "        memory = self.encoder(src)\n",
    "\n",
    "        tgt = self.embedding(tgt)\n",
    "\n",
    "        # Apply LayerNorm and Dropout after embedding\n",
    "        tgt = self.embedding_norm(tgt)\n",
    "        tgt = self.embedding_dropout(tgt)\n",
    "\n",
    "        tgt = self.pos_decoder(tgt)\n",
    "        tgt = tgt.permute(1, 0, 2)\n",
    "\n",
    "        tgt_mask = self.generate_square_subsequent_mask(\n",
    "            tgt.size(0)).to(tgt.device)\n",
    "\n",
    "        output: torch.Tensor = self.decoder(tgt, memory, tgt_mask=tgt_mask)\n",
    "        output = self.output(output)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        return output\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "138cdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "augument = transforms.Compose([\n",
    "    transforms.RandomRotation(15, expand=True, fill=(255,)),\n",
    "    transforms.RandomAffine(0, translate=(0.05, 0.05), fill=(255,)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.5, p=0.5, fill=(255,)),\n",
    "    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((64, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: 1.0 - x),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f6580b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\handwriting_recognition\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\handwriting_recognition\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = HandWritingDataset('words_data/train', transform=transform, label_transofrm=Params.encode_string, augument=augument) # augument data\n",
    "train_dataset = H5Dataset('train_data.h5', num_epochs=1)\n",
    "val_dataset = HandWritingDataset(root='words_data/val', transform=transform, label_transofrm=Params.encode_string)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, num_workers=0, sampler=train_dataset.create_h5_sampler(0), collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, num_workers=0, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "model = HandwritingTransformer(\n",
    "    input_size=16 * 24,\n",
    "    vocab_size=len(Params.vocab)+2,\n",
    "    d_model=128,\n",
    "    nhead_en=1,\n",
    "    num_layers_en=1,\n",
    "    nhead_de=1,\n",
    "    num_layers_de=1,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "history = TrainingHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6233e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:     1/1 100% | Elapsed:  14s | loss: 2.4976 - acc: 0.1305 | val_loss: 1.9832 - val_acc: 0.1732\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    train_loader=val_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    epochs=1,\n",
    "    early_stopping=early_stopping,\n",
    "    history=history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f4c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te            -  been        \n",
      "wnnnn         -  addition    \n",
      "tf            -  of          \n",
      "toa           -  gets        \n",
      "tn            -  is          \n",
      "whnhe         -  with        \n",
      "tanhe         -  much        \n",
      "tn            -  it          \n",
      "tn            -  as          \n",
      "tn            -  in          \n",
      "wahese        -  screws      \n",
      "the           -  the         \n",
      "aoef          -  from        \n",
      "th            -  to          \n",
      "aan           -  had         \n",
      "tan           -  last        \n",
      "wuheen        -  otherwise   \n",
      "the           -  the         \n",
      "aagnan        -  enigma      \n",
      "tase          -  lace        \n",
      "thrr          -  took        \n",
      "whuli         -  would       \n",
      "tf            -  for         \n",
      "tn            -  on          \n",
      "oof           -  for         \n",
      "aanth         -  must        \n",
      "aasse         -  heavy       \n",
      "weahh         -  better      \n",
      "then          -  this        \n",
      "on            -  is          \n",
      "th            -  to          \n",
      "wease         -  deaths      \n",
      "tn            -  is          \n",
      "thnee         -  will        \n",
      "toef          -  from        \n",
      "th            -  to          \n",
      "te            -  he          \n",
      "aaise         -  place       \n",
      "thnhe         -  with        \n",
      "ttnn          -  said        \n",
      "tea           -  rest        \n",
      "aaue          -  hopes       \n",
      "then          -  this        \n",
      "annhenn       -  authority   \n",
      "pnatn         -  against     \n",
      "weaaseennnd   -  reservations\n",
      "th            -  to          \n",
      "ahaiin        -  telling     \n",
      "ten           -  did         \n",
      "auhrr         -  ocean       \n",
      "tn            -  in          \n",
      "then          -  this        \n",
      "the           -  the         \n",
      "whnee         -  talks       \n",
      "the           -  those       \n",
      "the           -  the         \n",
      "aane          -  have        \n",
      "aann          -  saying      \n",
      "whs           -  was         \n",
      "o             -  a           \n",
      "aiaise        -  defences    \n",
      "ahna          -  taper       \n",
      "the           -  they        \n",
      "wnhhsn        -  actual      \n",
      "wnea          -  arms        \n",
      "tnd           -  and         \n",
      "auldi         -  jangly      \n",
      "ten           -  has         \n",
      "the           -  the         \n",
      "waniinn       -  million     \n",
      "tus           -  just        \n",
      "tene          -  back        \n",
      "wnhhne        -  attack      \n",
      "aean          -  being       \n",
      "on            -  it          \n",
      "whendn        -  transoms    \n",
      "aaeas         -  greatly     \n",
      "thni          -  calls       \n",
      "whe           -  them        \n",
      "the           -  the         \n",
      "aarrr         -  effort      \n",
      "tn            -  is          \n",
      "wand          -  mind        \n",
      "a             -  a           \n",
      "tn            -  in          \n",
      "airani        -  family      \n",
      "aenen         -  variety     \n",
      "te            -  be          \n",
      "oof           -  for         \n",
      "aan           -  sign        \n",
      "th            -  to          \n",
      "t             -  note        \n",
      "the           -  the         \n",
      "tane          -  have        \n",
      "of            -  of          \n",
      "whe           -  them        \n",
      "the           -  there       \n",
      "weaasaes      -  remember    \n",
      "t             -  we          \n",
      "the           -  the         \n",
      "wueulen       -  broadcast   \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_dataset = HandWritingDataset(root='words_data/val', transform=transform, label_transofrm=Params.encode_string)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=0, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "val_with_outs = ValidatorWithOutputs(model, criterion, device)\n",
    "outputs = val_with_outs.validate(test_loader)\n",
    "\n",
    "for i, (predicted, expected) in enumerate(outputs):\n",
    "    if i > 100:\n",
    "        break\n",
    "    predicted = Params.decode_string([i for i in predicted if i not in [27, 28]])\n",
    "    expected = Params.decode_string([i for i in expected if i not in [27, 28]])\n",
    "    print(f\"{predicted.ljust(12)}  -  {expected.ljust(12)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
